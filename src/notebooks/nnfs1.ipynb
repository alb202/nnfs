{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "import string\n",
    "import pickle\n",
    "# https://www.geeksforgeeks.org/implementation-of-neural-network-from-scratch-using-numpy/\n",
    "# https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('targets.pkl', 'wb') as file:\n",
    "#     pickle.dump(targets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('targets.pkl', 'wb') as file:\n",
    "    targets = pickle.loads(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "targets = dict()\n",
    "# A\n",
    "targets[\"a\"] = [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
    "\n",
    "# B\n",
    "targets[\"b\"] = [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
    "\n",
    "# C\n",
    "targets[\"c\"] = [0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
    "\n",
    "# D\n",
    "targets[\"d\"] = [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
    "\n",
    "# E\n",
    "targets[\"e\"] = [0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
    "\n",
    "# F\n",
    "targets[\"f\"] = [0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "# G\n",
    "targets[\"g\"] = [0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
    "\n",
    "# H\n",
    "targets[\"h\"] = [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "\n",
    "# I\n",
    "targets[\"i\"] = [0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n",
    "\n",
    "# J\n",
    "targets[\"j\"] = [0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
    "\n",
    "# # K\n",
    "# targets[\"k\"] = [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n",
    "\n",
    "number_of_targets = len(targets)\n",
    "\n",
    "# Creating labels\n",
    "training_labels = np.zeros((number_of_targets, number_of_targets))\n",
    "for i in range(0, number_of_targets):\n",
    "    training_labels[i, i] = 1\n",
    "# targets[\"y\"] = y\n",
    "\n",
    "\n",
    "# with open(\"targets.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(targets, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data and labels into numpy array\n",
    "\n",
    "\"\"\"\n",
    "Convert the matrix of 0 and 1 into one hot vector \n",
    "so that we can directly feed it to the neural network,\n",
    "these vectors are then stored in a list x.\n",
    "\"\"\"\n",
    "\n",
    "# Labels are also converted into NumPy array\n",
    "# y: np.array = np.array(targets.get('y'))\n",
    "# y: np.array = targets.pop('y')\n",
    "# training_labels: np.array = training_labels\n",
    "training_data: list = np.array([[np.array(value)] for value in targets.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A\n",
    "# a =[0, 0, 1, 1, 0, 0,\n",
    "#    0, 1, 0, 0, 1, 0,\n",
    "#    1, 1, 1, 1, 1, 1,\n",
    "#    1, 0, 0, 0, 0, 1,\n",
    "#    1, 0, 0, 0, 0, 1]\n",
    "# # B\n",
    "# b =[0, 1, 1, 1, 1, 0,\n",
    "#    0, 1, 0, 0, 1, 0,\n",
    "#    0, 1, 1, 1, 1, 0,\n",
    "#    0, 1, 0, 0, 1, 0,\n",
    "#    0, 1, 1, 1, 1, 0]\n",
    "# # C\n",
    "# c =[0, 1, 1, 1, 1, 0,\n",
    "#    0, 1, 0, 0, 0, 0,\n",
    "#    0, 1, 0, 0, 0, 0,\n",
    "#    0, 1, 0, 0, 0, 0,\n",
    "#    0, 1, 1, 1, 1, 0]\n",
    " \n",
    "# # Creating labels\n",
    "# y =[[1, 0, 0],\n",
    "#    [0, 1, 0],\n",
    "#    [0, 0, 1]]\n",
    "\n",
    "# x =[np.array(a).reshape(1, 30), np.array(b).reshape(1, 30), \n",
    "#                                 np.array(c).reshape(1, 30)]\n",
    " \n",
    "# number_of_targets = len(x)\n",
    "\n",
    "# # Labels are also converted into NumPy array\n",
    "# y = np.array(y)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set input parameters\n",
    "image_x_dimension = 5\n",
    "image_y_dimension = 6\n",
    "image_z_dimension = 1\n",
    "image_input_dimension = image_x_dimension * image_y_dimension * image_z_dimension\n",
    "number_of_output_classes = len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input data validation functions\n",
    "def validate_training_data(data: np.ndarray, n: int, x: int, y: int, z: int = 1) -> bool:\n",
    "    data_shape = data.shape\n",
    "\n",
    "    print(f'Number of samples in training data: {data_shape[0]}')\n",
    "    print(f'Depth of each sample in training data: {data_shape[1]}')\n",
    "    print(f'Length of array for each sample in training data: {data_shape[2]}')\n",
    "\n",
    "    assert data_shape[0] == n, f\"The number of training samples in the data is {data_shape[0]}; expected {n}\"\n",
    "    assert data_shape[1] == z, f\"The depth of each training sample is {data_shape[1]}; expected {z}\"\n",
    "    assert data_shape[2] == (x * y), f\"The length of each 1d training array is {data_shape[2]}; expected {x*y}\"\n",
    "\n",
    "### Input label validation functions\n",
    "def validate_training_labels(labels: np.ndarray, n: int) -> bool:\n",
    "    data_shape = labels.shape\n",
    "\n",
    "    print(f'Number of output classes in target data: {data_shape[0]}')\n",
    "    print(f'Length of array for each target label: {data_shape[1]}')\n",
    "\n",
    "    assert data_shape[0] == data_shape[0], f\"The target labels are shape {data_shape[0]} x {data_shape[1]}; expected a square\"\n",
    "    assert data_shape[0] == n, f\"The number of target labels is {data_shape[0]}; expected {n}\"\n",
    "    assert data_shape[1] == n, f\"The length of each target label array is {data_shape[1]}; expected {n}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the training data\n",
    "validate_training_data(data=training_data, n=number_of_output_classes, x=image_x_dimension, y=image_y_dimension, z=image_z_dimension)\n",
    "validate_training_labels(labels=training_labels, n=number_of_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting data and labels into numpy array\n",
    "\n",
    "# \"\"\"\n",
    "# Convert the matrix of 0 and 1 into one hot vector \n",
    "# so that we can directly feed it to the neural network,\n",
    "# these vectors are then stored in a list x.\n",
    "# \"\"\"\n",
    "# x: list = [np.array(values).reshape(1, 30) for values in targets.values()]\n",
    "\n",
    "# # Labels are also converted into NumPy array\n",
    "# # y: np.array = np.array(targets.get('y'))\n",
    "# y: np.array = targets.get('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = generate_wt(30, 15)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "def sigmoid(x: np.ndarray[np.ndarray[float, ...]]) -> np.ndarray[np.ndarray[float, ...]]:\n",
    "\treturn 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x: np.ndarray[np.ndarray[float, ...]]) -> np.ndarray[np.ndarray[float, ...]]:\n",
    "\treturn np.maximum(0, x)\n",
    "\n",
    "def tanh(x: np.ndarray[np.ndarray[float, ...]]) -> np.ndarray[np.ndarray[float, ...]]:\n",
    "\treturn (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "\n",
    "\n",
    "hidden_activation_function = sigmoid\n",
    "output_activation_function = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = np.random.randn(500)\n",
    "# DataFrame({'original': tmp, 'transformed': sigmoid(tmp)}).plot.scatter(x='original', y='transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Feed forward neural network\n",
    "# 1 Input layer(1, 30)\n",
    "# 1 hidden layer (1, 5)\n",
    "# 1 output layer(3, 3)\n",
    "\n",
    "# def f_forward(x, w1, w2) -> np.ndarray[np.ndarray[float]]:\n",
    "# \t# hidden\n",
    "# \tz1: np.ndarray[np.ndarray[float]] = x.dot(w1)# input from layer 1\n",
    "# \ta1: np.ndarray[np.ndarray[float]] = hidden_activation_function(z1)# out put of layer 2 \n",
    "\n",
    "# \t# Output layer\n",
    "# \tz2: np.ndarray[np.ndarray[float]] = a1.dot(w2)# input of out layer\n",
    "# \ta2: np.ndarray[np.ndarray[float]] = output_activation_function(z2)# output of out layer\n",
    "# \treturn(a2)\n",
    "\n",
    "def f_forward(*weights, x) -> np.ndarray[np.ndarray[float, ...]]:\n",
    "\n",
    "\toutput: np.ndarray[np.ndarray[float]] = None\n",
    "\n",
    "\tfor i, w in enumerate(weights):\n",
    "\n",
    "\t\tif i == 0:\n",
    "\t\t\tz: np.ndarray[np.ndarray[float]] = x.dot(w)# input from layer 1\n",
    "\t\telse:\n",
    "\t\t\tz: np.ndarray[np.ndarray[float]] = output.dot(w)# input from layer 1\n",
    "\n",
    "\t\tif i < len(weights) - 1:\n",
    "\t\t\toutput: np.ndarray[np.ndarray[float]] = hidden_activation_function(z)# out put of layer 2 \n",
    "\t\telse:\n",
    "\t\t\toutput: np.ndarray[np.ndarray[float]] = output_activation_function(z)# out put of layer 2 \n",
    "\n",
    "\treturn(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the weights randomly\n",
    "def generate_wt(x: int, y: int) -> np.ndarray:\n",
    "    return np.random.randn(x, y)\n",
    "\t# list_of_weights: list = []\n",
    "\t# for _ in range(x * y):\n",
    "\t# \tlist_of_weights.append(np.random.randn())\n",
    "\t# return(np.array(list_of_weights).reshape(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_wt(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loss we will be using mean square error(MSE)\n",
    "def loss(out: np.ndarray[np.ndarray[float]], Y: np.ndarray) -> float:\n",
    "\t# print('out', out, type(out))\n",
    "\t# print('Y', Y, type(Y))\n",
    "\ts: float = np.square(out-Y)\n",
    "\ts: float = np.sum(s) / len(Y)\n",
    "\treturn(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Back propagation of error \n",
    "# def back_propagation(*weights, x, y, alpha: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "# \tw1 = weights[0]\n",
    "# \tw2 = weights[1]\n",
    "\n",
    "# \t# print('x', x.shape)\n",
    "# \t# print('y', y.shape)\n",
    "\n",
    "# \t# # hidden layer\n",
    "# \t# z1: np.ndarray[np.ndarray[float]] = x.dot(w1) # input from layer 1 \n",
    "# \t# layer_output_1: np.ndarray[np.ndarray[float]] = hidden_activation_function(z1) # output of layer 2 \n",
    "# \t# # print('z1', z1, type(z1), type(z1[0]))\n",
    "# \t# # print('a1', a1, type(a1), type(a1[0]))\n",
    "\n",
    "# \t# # print('z1', z1.shape)\n",
    "# \t# # print('a1', z1.shape)\n",
    "\n",
    "# \t# # Output layer\n",
    "# \t# z2: np.ndarray[np.ndarray[float]] = layer_output_1.dot(w2) # input of out layer\n",
    "# \t# layer_output_2: np.ndarray[np.ndarray[float]] = output_activation_function(z2) # output of out layer\n",
    "\t\n",
    "# \toutputs: np.ndarray[np.ndarray[float]] = []\n",
    "\n",
    "# \tfor i, w in enumerate(weights):\n",
    "\n",
    "# \t\tif i == 0:\n",
    "# \t\t\tz: np.ndarray[np.ndarray[float]] = x.dot(w)# input from layer 1\n",
    "# \t\telse:\n",
    "# \t\t\tz: np.ndarray[np.ndarray[float]] = outputs[i-1].dot(w)# input from layer 1\n",
    "\n",
    "# \t\tif i < len(weights) - 1:\n",
    "# \t\t\toutput: np.ndarray[np.ndarray[float]] = hidden_activation_function(z)# out put of layer 2 \n",
    "# \t\telse:\n",
    "# \t\t\toutput: np.ndarray[np.ndarray[float]] = output_activation_function(z)# out put of layer 2 \n",
    "\t\t\n",
    "# \t\toutputs.append(output)\n",
    "\t\n",
    "# \tlayer_output_1 = outputs[0]\n",
    "# \t# layer_output_2 = outputs[1]\n",
    "\n",
    "# \toutput_error: np.ndarray[np.ndarray[float]] = (outputs[-1] - y)\n",
    "# \toutput_delta = w2.dot(output_error.transpose()).transpose()\n",
    "\t\n",
    "# \tlayer_1_delta = layer_output_1 * (1 - layer_output_1)\n",
    "\t\n",
    "# \t# for each layer, do you multply all the deltas?\n",
    "# \tlayer_1_error: np.ndarray[np.ndarray[float]] = np.multiply(output_delta, layer_1_delta)\n",
    "\n",
    "# \t# print('d2', d2.shape)\n",
    "# \t# print('d1', d1.shape)\n",
    "\n",
    "# \t# Gradient for w1 and w2\n",
    "# \tw1_gradient: np.ndarray[np.ndarray[float]] = x.transpose().dot(layer_1_error)\n",
    "# \tw2_gradient: np.ndarray[np.ndarray[float]] = layer_output_1.transpose().dot(output_error)\n",
    "\n",
    "# \t# Updating parameters\n",
    "# \tupdated_w1: np.ndarray[np.ndarray[float]] = weights[0]-(alpha*(w1_gradient))\n",
    "# \tupdated_w2: np.ndarray[np.ndarray[float]] = weights[1]-(alpha*(w2_gradient))\n",
    "\n",
    "# \treturn(updated_w1, updated_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back propagation of error \n",
    "def back_propagation(*weights, x, y, alpha: float) -> tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "\t# w1 = weights[0]\n",
    "\t# w2 = weights[1]\n",
    "\n",
    "\t# print('x', x.shape)\n",
    "\t# print('y', y.shape)\n",
    "\n",
    "\t# # hidden layer\n",
    "\t# z1: np.ndarray[np.ndarray[float]] = x.dot(w1) # input from layer 1 \n",
    "\t# layer_output_1: np.ndarray[np.ndarray[float]] = hidden_activation_function(z1) # output of layer 2 \n",
    "\t# # print('z1', z1, type(z1), type(z1[0]))\n",
    "\t# # print('a1', a1, type(a1), type(a1[0]))\n",
    "\n",
    "\t# # print('z1', z1.shape)\n",
    "\t# # print('a1', z1.shape)\n",
    "\n",
    "\t# # Output layer\n",
    "\t# z2: np.ndarray[np.ndarray[float]] = layer_output_1.dot(w2) # input of out layer\n",
    "\t# layer_output_2: np.ndarray[np.ndarray[float]] = output_activation_function(z2) # output of out layer\n",
    "\n",
    "\tlayer_outputs: list = []\n",
    "\toutput_errors: list = []\n",
    "\toutput_deltas: list = []\n",
    "\t# output_gradients: list = []\n",
    "\toutput_weights: list = []\n",
    "\n",
    "\tfor i, w in enumerate(weights):\n",
    "\n",
    "\t\tif i == 0:\n",
    "\t\t\tz: np.ndarray[np.ndarray[float]] = x.dot(w)# input from layer 1\n",
    "\t\telse:\n",
    "\t\t\tz: np.ndarray[np.ndarray[float]] = layer_outputs[i-1].dot(w)# input from layer 1\n",
    "\n",
    "\t\tif i < len(weights) - 1:\n",
    "\t\t\toutput: np.ndarray[np.ndarray[float]] = hidden_activation_function(z)# out put of layer 2 \n",
    "\t\telse:\n",
    "\t\t\toutput: np.ndarray[np.ndarray[float]] = output_activation_function(z)# out put of layer 2 \n",
    "\n",
    "\t\tlayer_outputs.append(output)\n",
    "\n",
    "\t# layer_output_2 = outputs[1]\n",
    "\tfor i in range(len(layer_outputs) - 1, -1, -1):\n",
    "\t\tif i == len(layer_outputs) - 1:\n",
    "\t\t\terror = (layer_outputs[i] - y)\n",
    "\t\t\tdelta = weights[-1].dot(error.transpose()).transpose()\n",
    "\t\t\toutput_errors.insert(0, error)\n",
    "\t\t\toutput_deltas.insert(0, delta)\n",
    "\t\telse:\n",
    "\t\t\tlayer_output = layer_outputs[i]\n",
    "\t\t\tlayer_delta = layer_output * (1 - layer_output)\n",
    "\t\t\thidden_layer_error = np.multiply(output_deltas[0], layer_delta)\n",
    "\t\t\toutput_errors.insert(0, hidden_layer_error)\n",
    "\t\t\toutput_deltas.insert(0, layer_delta)\n",
    "\n",
    "\t# output_error: np.ndarray[np.ndarray[float]] = (layer_outputs[-1] - y)\n",
    "\t# output_delta = w2.dot(output_error.transpose()).transpose()\n",
    "\n",
    "\t# layer_output_1 = layer_outputs[0]\n",
    "\t# layer_1_delta = layer_output_1 * (1 - layer_output_1)\n",
    "\n",
    "\n",
    "\t# # for each layer, do you multply all the deltas?\n",
    "\t# layer_1_error: np.ndarray[np.ndarray[float]] = np.multiply(output_delta, layer_1_delta)\n",
    "\n",
    "\t# print('d2', d2.shape)\n",
    "\t# print('d1', d1.shape)\n",
    "\tfor i, output_error in enumerate(output_errors):\n",
    "\t\tif i == 0:\n",
    "\t\t\tgradient = x.transpose().dot(output_error)\n",
    "\t\telse:\n",
    "\t\t\tgradient = layer_outputs[i-1].transpose().dot(output_error)# input from layer 1\n",
    "\t\toutput_weight = weights[i] - (alpha * gradient)\n",
    "\t\toutput_weights.append(output_weight)\n",
    "\t\t# output_gradients.append(gradient)\n",
    "\n",
    "\t# # Gradient for w1 and w2\n",
    "\t# w1_gradient: np.ndarray[np.ndarray[float]] = x.transpose().dot(output_errors[0])\n",
    "\t# w2_gradient: np.ndarray[np.ndarray[float]] = layer_outputs[0].transpose().dot(output_errors[1])\n",
    "\n",
    "\t# # Updating parameters\n",
    "\t# updated_w1: np.ndarray[np.ndarray[float]] = weights[0]-(alpha*(output_gradients[0]))\n",
    "\t# updated_w2: np.ndarray[np.ndarray[float]] = weights[1]-(alpha*(output_gradients[1]))\n",
    "\n",
    "\t# return(updated_w1, updated_w2)\n",
    "\n",
    "\treturn tuple(output_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [1,2,3]\n",
    "for i in range(len(tmp)-1, -1, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple([2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(*[np.array([1,2, 4]),np.array([3,4,5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(*weights, x, Y, alpha: float = 0.01, epoch: int = 10) -> tuple[list, list, np.ndarray, np.ndarray]:\n",
    "\n",
    "\t# w1 = initial_weights[0]\n",
    "\t# w2 = initial_weights[1]\n",
    "\n",
    "\t# print('x', x, len(x))\n",
    "\taccuracy: list = []\n",
    "\tloss_: list = []\n",
    "\n",
    "\tfor j in range(epoch):\n",
    "\t\tepoch_losses: list = []\n",
    "\t\tfor i in range(len(x)):\n",
    "\t\t\t# out: np.ndarray[np.ndarray[float]] = f_forward(x[i], w1, w2)\n",
    "\t\t\tout: np.ndarray[np.ndarray[float]] = f_forward(*weights, x=x[i])\n",
    "\t\t\tloss_value: float = loss(out=out, Y=Y[i])\n",
    "\t\t\tepoch_losses.append(loss_value)\n",
    "\t\t\tweights = back_propagation(*weights, x=x[i], y=Y[i], alpha=alpha)\n",
    "\t\tprint(\"epochs:\", j + 1, \"======== acc:\", (1-(sum(epoch_losses)/len(x)))*100) \n",
    "\t\taccuracy.append((1-(sum(epoch_losses)/len(x)))*100)\n",
    "\t\tloss_.append(sum(epoch_losses) / len(x))\n",
    "\treturn(weights, accuracy, loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(*weights, x) -> int:\n",
    "\n",
    "\tfeed_forward_output: np.ndarray[np.ndarray[float]] = f_forward(*weights, x=x)\n",
    "\t# print(feed_forward_output, sum(sum(feed_forward_output)))\n",
    "\t# maxm: int = 0\n",
    "\t# k: int = 0\n",
    "\t# for i in range(len(feed_forward_output[0])):\n",
    "\t# \tif(maxm < feed_forward_output[0][i]):\n",
    "\t# \t\tmaxm = feed_forward_output[0][i]\n",
    "\t# \t\tk = i\n",
    "\t# k = feed_forward_output[0].index(max(feed_forward_output[0]))\n",
    "\tk = feed_forward_output.argmax()\n",
    "\tplt.imshow(x.reshape(5, 6))\n",
    "\tplt.show()\n",
    "\n",
    "\treturn k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%timeit\n",
    "# # maxm: int = 0\n",
    "# # k: int = 0\n",
    "# feed_forward_output = np.array([[1.33457852e-03, 9.53068532e-05, 2.73656253e-03, \n",
    "# 2.81552447e-03, 3.79061500e-03, 6.59064529e-03,9.19052338e-05, 4.48017812e-04, 9.83174057e-01,2.74596253e-03, 2.91937077e-05]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# maxm: int = 0\n",
    "# # k: int = 0\n",
    "# for i in range(len(feed_forward_output[0])):\n",
    "#     if(maxm < feed_forward_output[0][i]):\n",
    "#         maxm = feed_forward_output[0][i]\n",
    "#         k = i\n",
    "# k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# k = feed_forward_output.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%timeit\n",
    "# k = feed_forward_output[0].index(max(feed_forward_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = [[0.84815273, 0.04205895, 0.0031815, 0.01468254, 0.00505702, 0.10068009, 0.00123184, 0.0093114, 0.03034115, 0.00106627, 0.00247928]]\n",
    "# Y = y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_wt(*(4, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1: np.ndarray = generate_wt(image_input_dimension, 15)\n",
    "# w2: np.ndarray = generate_wt(15, number_of_targets)\n",
    "# # print(w1, \"\\n\\n\", w2)\n",
    "\n",
    "nn_layers = [\n",
    "    (image_input_dimension, 150), \n",
    "    (150, number_of_targets)\n",
    "    ]\n",
    "initial_weights = [generate_wt(*layer_dimensions) for layer_dimensions in nn_layers]\n",
    "\n",
    "\"\"\"The arguments of train function are data set list x, \n",
    "correct labels y, weights w1, w2, learning rate = 0.1, \n",
    "no of epochs or iteration.The function will return the\n",
    "matrix of accuracy and loss and also the matrix of \n",
    "trained weights w1, w2\"\"\"\n",
    "\n",
    "trained_weights, accuracy_results, loss_results = train(*initial_weights, x=training_data, Y=training_labels, alpha=0.1, epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting accuracy\n",
    "plt.plot(accuracy_results)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel(\"Epochs:\")\n",
    "plt.show()\n",
    "\n",
    "# plotting Loss\n",
    "plt.plot(loss_results)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel(\"Epochs:\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The predict function will take the following arguments:\n",
    "1) image matrix\n",
    "2) w1 trained weights\n",
    "3) w2 trained weights\n",
    "\"\"\"\n",
    "\n",
    "# target_characters = list(string.ascii_lowercase)[0: number_of_targets]\n",
    "random_target_character: str = random.choice(list(targets.keys()))\n",
    "random_target_array: np.array = targets.get(random_target_character)\n",
    "random_target_character, random_target_array\n",
    "\n",
    "print('Character to predict: ', random_target_character)\n",
    "predict_array = np.asarray(random_target_array).reshape(1, 30)\n",
    "\n",
    "output = predict(*trained_weights, x=predict_array)\n",
    "('Predicted letter: ', output, list(targets.keys())[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp = np.array([[0.55808578 ,0.9860626 , 0.9742969,  0.00516912 ,0.98360591 ,0.06539192,\n",
    "  0.00998272 ,0.02447332, 0.24575064 ,0.99329634, 0.30919278 ,0.7771927,\n",
    "  0.51599149, 0.95019494 ,0.01692725]] )\n",
    "print(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(tmp, (1-tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.multiply(tmp, (1-tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tmp * (1-tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(sum(output[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.asarray(list(targets.values())[1]).reshape(5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
